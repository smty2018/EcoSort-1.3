{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQWd1RVj6LBO",
        "outputId": "bd420540-49e2-444e-8b56-70b55b990d5e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J_krunW7BP5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zONT7r3G7E-o"
      },
      "outputs": [],
      "source": [
        "dataset_dir = \"kaggle/input/garbage-classification-6-classes-775class\"\n",
        "\n",
        "class_labels = os.listdir(dataset_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVjT03XL8ggV",
        "outputId": "bde48ae1-4e46-4ea9-d93f-6966ffe69d58"
      },
      "outputs": [],
      "source": [
        "class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TdxAY2HO6-hL",
        "outputId": "99d19133-db55-4598-9cba-2fa609347a0a"
      },
      "outputs": [],
      "source": [
        "num_samples_per_class = 3\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, label in enumerate(class_labels, start=1):\n",
        "    # image filenames for the current class\n",
        "    image_files = os.listdir(os.path.join(dataset_dir, label))\n",
        "\n",
        "    sample_images = random.sample(image_files, num_samples_per_class)\n",
        "\n",
        "    for j, image_file in enumerate(sample_images, start=1):\n",
        "\n",
        "        plt.subplot(len(class_labels), num_samples_per_class, (i-1)*num_samples_per_class + j)\n",
        "        img = mpimg.imread(os.path.join(dataset_dir, label, image_file))\n",
        "        plt.imshow(img)\n",
        "        \n",
        "        plt.title(f\"Class: {label}\")\n",
        "        plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGNsspbX8z5a"
      },
      "outputs": [],
      "source": [
        "class_distribution = {label: len(os.listdir(os.path.join(dataset_dir, label))) for label in class_labels}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "JqPvBP5H9Rd6",
        "outputId": "5f8979f4-57f5-4f70-9a16-e1dcbcc664de"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(class_distribution.keys(), class_distribution.values())\n",
        "plt.xlabel('Class')\n",
        "\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Class Distribution')\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mygjW6Vo-u6K"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet import preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Vga7DmqBsXX"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image_path, target_size=(224, 224)):\n",
        "\n",
        "\n",
        "    img = image.load_img(image_path, target_size=target_size)\n",
        "\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_batch = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    img_preprocessed = preprocess_input(img_batch)\n",
        "\n",
        "\n",
        "    return img_preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "r7wnEmUS-ZGX",
        "outputId": "2edeba10-8774-443b-9378-860434a1430b"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def plot_images(original, preprocessed):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    axs[0].imshow(original)\n",
        "    axs[0].set_title('Original Image')\n",
        "    axs[0].axis('off')\n",
        "\n",
        "    preprocessed_image = np.squeeze(preprocessed, axis=0)\n",
        "    axs[1].imshow(preprocessed_image)\n",
        "    axs[1].set_title('Preprocessed Image')\n",
        "    axs[1].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "image_path = \"kaggle/input/garbage-classification-6-classes-775class/battery/battery102.jpg\"\n",
        "preprocessed_image = preprocess_image(image_path)\n",
        "original_image = cv2.imread(image_path)\n",
        "plot_images(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB), preprocessed_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0iVwdBiDSUD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIfnRsOSDcjc"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "for label_index, label in enumerate(class_labels):\n",
        "    label_dir = os.path.join(dataset_dir, label)\n",
        "\n",
        "    for image_file in os.listdir(label_dir):\n",
        "        image_path = os.path.join(label_dir, image_file)\n",
        "\n",
        "        image = load_img(image_path, target_size=(224, 224))\n",
        "        image = img_to_array(image)\n",
        "        \n",
        "        image = np.expand_dims(image, axis=0)\n",
        "        image = image / 255.0 \n",
        "         # Normalize\n",
        "        X.append(image)\n",
        "        y.append(label_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVBjqXWPDpVP"
      },
      "outputs": [],
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zloTb2UDDsTB"
      },
      "outputs": [],
      "source": [
        "y = to_categorical(y, num_classes=len(class_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-AQbP4QDv_b"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awsdNvv3EEad"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tensorflow.keras.applications import VGG16, VGG19, ResNet50, ResNet152, MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUZ--2MPElq9"
      },
      "outputs": [],
      "source": [
        "num_classes=6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(-1, 224, 224, 3)\n",
        "X_test = X_test.reshape(-1, 224, 224, 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8MiRUXUEIMn"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, name, X_train, y_train, X_test, y_test):\n",
        "    print(f\"Evaluating {name}...\")\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
        "    \n",
        "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
        "\n",
        "    print(f\"Accuracy of {name}: {accuracy}\")\n",
        "    print(classification_report(np.argmax(y_test, axis=1), y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuNAisy1ENHo",
        "outputId": "db2170ad-505f-414f-fa27-2731c0510b70"
      },
      "outputs": [],
      "source": [
        "# VGG16\n",
        "base_model = VGG16(weights='imagenet', include_top=False)\n",
        "x = base_model.output\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "predictions = Dense(6, activation='softmax')(x)\n",
        "\n",
        "vgg16_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "evaluate_model(vgg16_model, \"VGG16\", X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANKW-X2eEbIF"
      },
      "outputs": [],
      "source": [
        "base_model = VGG19(weights='imagenet', include_top=False)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "vgg19_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "evaluate_model(vgg19_model, \"VGG19\", X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD3BkL6KEeYY"
      },
      "outputs": [],
      "source": [
        "# ResNet50\n",
        "base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "x = base_model.output\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "resnet50_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "evaluate_model(resnet50_model, \"ResNet50\", X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqEuCFeKEhl1"
      },
      "outputs": [],
      "source": [
        "base_model = ResNet152(weights='imagenet', include_top=False)\n",
        "x = base_model.output\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "resnet152_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "evaluate_model(resnet152_model, \"ResNet152\", X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StJj9haEEkD2"
      },
      "outputs": [],
      "source": [
        "# MobileNetV2\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "mobilenetv2_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "evaluate_model(mobilenetv2_model, \"MobileNetV2\", X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "num_classes = y_train.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_vgg19_model(input_shape, num_classes):\n",
        "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_resnet152_model(input_shape, num_classes):\n",
        "    base_model = ResNet152(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    \n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "vgg19_weight = 0.1\n",
        "resnet152_weight = 0.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Final Model=Weighted Ensemble Model of VGG19 and RESNET152"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "vgg19_model = create_vgg19_model(input_shape, num_classes)\n",
        "\n",
        "vgg19_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "vgg19_model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "\n",
        "resnet152_model = create_resnet152_model(input_shape, num_classes)\n",
        "resnet152_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "resnet152_model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "\n",
        "vgg19_predictions = vgg19_model.predict(X_test)\n",
        "resnet152_predictions = resnet152_model.predict(X_test)\n",
        "\n",
        "#weighted average\n",
        "weighted_predictions = (vgg19_weight * vgg19_predictions) + (resnet152_weight * resnet152_predictions)\n",
        "\n",
        
        "weighted_ensemble_accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(weighted_predictions, axis=1))\n",
        "#print(\"Weighted Ensemble Accuracy:\", weighted_ensemble_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def weighted_ensemble(models, weights):\n",
        "\n",
        "    ensemble_inputs = [model.input for model in models]\n",
        "\n",
        "    ensemble_outputs = [model.output for model in models]\n",
        "    weighted_average = Dense(6, activation='softmax', name='weighted_average')(ensemble_outputs)\n",
        "\n",
        "    weighted_model = Model(inputs=ensemble_inputs, outputs=weighted_average)\n",
        "\n",
        "    weighted_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return weighted_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weighted_ensemble_model = weighted_ensemble([vgg19_model, resnet152_model], [0.1, 0.9])  \n",
        "\n",
        "\n",
        "weighted_ensemble_model.save(\"abc.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
